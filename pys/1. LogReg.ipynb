{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization: 1.207113265991211ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a, b)\n",
    "toc = time.time()\n",
    "print(\"Vectorization: \"+str((toc-tic)*1000)+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For loop: 581.8850994110107ms\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i]*b[i]\n",
    "toc = time.time()\n",
    "print(\"For loop: \"+str((toc-tic)*1000)+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 4 6]\n",
      " [1 1 5 8]\n",
      " [1 3 9 9]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[5, 0, 4, 6],\n",
    "            [1, 1, 5, 8],\n",
    "            [1, 3, 9, 9]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  4 18 23]\n"
     ]
    }
   ],
   "source": [
    "# 对矩阵按列求和\n",
    "cal = A.sum(axis=0)\n",
    "print(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71.42857143  0.         22.22222222 26.08695652]\n",
      " [14.28571429 25.         27.77777778 34.7826087 ]\n",
      " [14.28571429 75.         50.         39.13043478]]\n"
     ]
    }
   ],
   "source": [
    "# 广播\n",
    "perc = 100*A/cal.reshape(1, 4)\n",
    "print(perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# math实现sigmoid函数\n",
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    s = 1/(1 + math.exp(-x))\n",
    "    return s\n",
    "\n",
    "basic_sigmoid(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy实现sigmoid函数\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19661193, 0.10499359, 0.04517666])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_gradient(x):\n",
    "    s = sigmoid(x)\n",
    "    ds = s*(1-s)\n",
    "    return ds\n",
    "\n",
    "sigmoid_gradient(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.80897665e-01, 8.94462891e-04, 1.79657674e-02, 1.21052389e-04,\n",
       "        1.21052389e-04],\n",
       "       [8.78679856e-01, 1.18916387e-01, 8.01252314e-04, 8.01252314e-04,\n",
       "        8.01252314e-04]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    x_exp = np.exp(x)\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / x_sum\n",
    "    return s\n",
    "\n",
    "x2 = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "softmax(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n",
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "def L1(yhat, y):\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "    return loss\n",
    "\n",
    "def L2(yhat, y):\n",
    "    loss = np.dot(y-yhat, (y-yhat).T)\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat, y)))\n",
    "print(\"L2 = \" + str(L2(yhat, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 图形库\n",
    "import matplotlib.pyplot as plt\n",
    "# 处理H5格式的数据集\n",
    "import h5py\n",
    "# 科学计算库\n",
    "import scipy\n",
    "# 图像处理库\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "# 自定义py文件\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros(dim, 1)\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    # training set size\n",
    "    m = X.shape[1]\n",
    "    # activations\n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    # cost function\n",
    "    cost = -1/m * np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    \n",
    "    # back propagation\n",
    "    dZ = A - Y\n",
    "    dw = 1/m * np.dot(X, dZ.T)\n",
    "    db = 1/m * np.sum(dZ)\n",
    "    \n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, iterations, learning_rate, print_cost):\n",
    "    costs = []\n",
    "    for i in range(iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print(\"Cost after %i iterations: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\n",
    "        \"w\": w,\n",
    "        \"b\": b\n",
    "    }\n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    return params, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_pred = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X)+b)\n",
    "    for i in range(m):\n",
    "        if A[0, i] <= 0.5:\n",
    "            Y_pred[0, i] = 0\n",
    "        else:\n",
    "            Y_pred[0, i] = 1\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(X_train, Y_train, X_test, Y_test, iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    # 初始化参数\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    \n",
    "    # 训练，优化参数\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, iterations, learning_rate, print_cost)\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    # 评估结果\n",
    "    Y_pred_train = predict(w, b, X_train)\n",
    "    Y_pred_test = predict(w, b, X_test)\n",
    "    train_accuracy = 100 - np.mean(np.abs(Y_train - Y_pred_train))*100\n",
    "    test_accuracy = 100 - np.mean(np.abs(Y_test - Y_pred_test))*100\n",
    "    \n",
    "    res = {\n",
    "        \"w\": w,\n",
    "        \"b\": b,\n",
    "        \"iterations\": iterations,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"prediction_train\": Y_pred_train,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"prediction_test\": Y_pred_test,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
