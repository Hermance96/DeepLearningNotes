# Keras笔记

* Keras是一个模型级的库，不负责处理张量操作、求微分等运算，交给张量库，也就是Keras的后端引擎 backend engine 来处理。
* 采用 Tensorflow 作为 Keras 的后端引擎，它应用广泛，可扩展性好，可用于生产环境。
* 安装的版本号为
    * tensorflow@1.13.1
    * tensorflow-base@1.13.1
    * tensorflow-estimator@1.13.0
    * keras@2.2.4
    * keras-base@2.2.4
    * keras-applications@1.0.8
    * keras-preprocessing@1.1.0

## 基础知识
### 张量
    张量 tensor 是一种数据容器，矩阵是二阶张量，张量是矩阵向任意维度的推广。
* 关键属性：
    * 阶，轴的个数，查看属性 ndim
    * 形状，张量沿每个轴的维度大小（元素个数），查看属性 shape
    * 数据类型，查看属性 dtype
* 张量切片 slice，沿着某个轴截取 [startIdx:endIdx]，表示从该轴的 startIdx 到 endIdx-1 的部分。如果采取了负数索引，就表示到该轴终点的相对位置。
* 张量运算
    * 广播 broadcast，高阶张量和低阶张量相加，会将低阶张量进行广播，添加新的广播轴，使其 ndim 和高阶的相同，然后沿着新轴不断重复，到形状和高阶的相同，最后逐元素计算。
    * 点积运算 tensor product，不是逐元素的乘积，调用方法 np.dot()
    * 张量变形，调用方法 reshape，变形后总元素的个数不变

### 算法描述
* 小批量随机梯度下降，即**小批量SGD**
    * 随机抽取样本x和对应y组成的数据批量
    * 前向传播，得到预测值y_pred
    * 计算损失函数
    * 后向传播，计算梯度
    * 根据梯度更新参数
* 每次迭代在所有数据上运行，称为**批量SGD**

### 计算流程
1. 加载数据集，以第一个例子，识别手写数字为例。
2. 设计网络架构
    * 层layer，是模型的组成构建，从输入数据中提取表示，通过链接多个层，实现渐进式的数据蒸馏 data distillation
    * 在本例中，模型包含2个全连接层FC，第二层是一个10路softmax分类层，返回图像属于各个数字的概率
3. 配置学习过程
    * 损失函数 loss function，训练过程中需要将其最小化，为学习提供反馈信号
    * 优化器 optimizer，决定基于损失函数，如何对网络参数进行更新
    训练和测试过程中需要监控的指标 metrics
4. 调整数据格式
    * 调整输入数据维度和数据格式，准备输出的标签
5. 训练模型
    * 调用 fit() 方法，指定 epochs 和 batch_size
    * 模型不会同时处理整个数据集，而是会拆分成小批量处理，这里批量的尺寸就是 batch_size
6. 评估模型
    * 最后用 evaluate() 方法评估模型在测试集上的表现

### 举例
1. 影评中的感情（正面/负面）——二分类问题
* 加载keras的IMDB数据集，然后进行张量化处理
    * train_data是一个25000维度的一阶向量，采用onehot编码，因为向量的数据范围都在0到9999之间，所以将每一个数扩展为一个长度为10000的数组，除了该数所在的位置取1，其余位置都填充0
    * 处理完之后，训练集为，X (25000, 10000), Y(25000, 1)
* 构建网络
    * 对于输入向量，输出{0, 1}的情况，采用relu激活的全连接层FC的简单堆叠，称之为 Dense，在这种问题上表现很好。
    * 本例中，设计的网络结构是，两层FC，均包含16个单元，采取relu激活函数；最后输出层只有1个单元，采取sigmoid激活函数。
    * 二分分类，最好采取二元交叉熵 binary_crossentropy 作为损失函数
    * RMSprop 是一个常见的优化器
* 方法验证
    * 将测试集留出一部分作为验证集，观察模型的表现；
    * 通过model.fit()训练模型，返回一个History对象，对象成员history是一个字典，包含训练过程中所有的数据。这里键值包含loss, acc, val_loss, val_acc，分别是训练集的损失、准确率，还有验证集的损失、准确率。
    * 从下图的对比可以看出，在 epochs=4 左右，就可以停下来了，否则会出现针对于训练集过拟合的情况。

<img src="imgs/movie1.png" width="800"> 

* 模型评估
    * 重新训练模型，设置训练轮数为4，调用evaluate()评估模型在测试集上的表现，准确率达到 87.4%

2. 新闻分类——多分类问题
* 加载keras中的reuters数据集，进行张量化处理后：
    * train_X (8982, 10000)
    * train_Y (8982, 46)
    * test_X (2246, 10000)
    * test_Y (2246, 46)
    * 输出结果为分别属于46个类别的概率，概率之和为1
* 构建网络
    * 本例中，设计的网络结构是，两层FC，均包含64个单元，采取relu激活函数；最后输出层有46个单元，采取 softmax 激活函数。
    * 中间隐藏层的单元数必须大于输出的单元数，否则就会产生信息瓶颈，相当于将信息压缩到维度很小的中间空间，必然会导致模型表现下降。
    * 多分类采取的损失函数为，多类交叉熵 categorical_crossentropy
    * 优化器依然采用 RMSprop
* 方法验证
    * 留出验证集。经验证，经过9轮左右的训练，就会发生过拟合。
* 模型评估
    * 最后在测试集上的表现为，准确率 77.6%

3. 波士顿房价预测——回归问题
* 加载keras中的boston_housing房价数据集：
    * train_X (404, 13)
    * test_Y (102, 13)
    * 然后进行归一化处理，求出训练集的平均值和标准差，将训练集和测试集的数据都减去平均值，再除以标准差。
* 构建网络
    * 本例中，设计的网络结构是，两层FC，均包含64个单元，采取relu激活函数；最后输出层只有1个单元，无激活函数。
    * 损失函数为，均方误差 mse，预测值和真实值误差的平方。
    * 评估标准为，平均绝对误差 mae，预测值和真实值误差的绝对值。
    * 优化器依然采用 RMSprop
* 方法验证
    * 设计K折交叉验证。每次取1/k的数据作为验证集，训练集中剩下的数据作为训练集；
    * 每次都新建模型，然后调用fit()，进行训练，记录下在当前验证集上的表现；
    * 根据验证集的表现，调整训练轮数，避免训练集过拟合。
* 模型评估
    * 最后选择训练轮数为60左右，这是在验证集上表现最好的参数。
    * 在测试集上的表现为，mae=2.64

### 机器学习通用流程
1. 定义问题，收集数据集。
    * 明确输入、输出，和可用数据，假设可用数据包含足够多的信息，可以用于学习输入和输出之间的关系。
    * 注意到，机器学习是基于训练数据中存在的过去的数据，来预测未来，所以未来和过去规律相同时效果更好。
2. 选择衡量指标。
    * 精度，准确率，召回率？
    * 根据业务目标设置衡量指标。
3. 确定评估方法。
    * 留出验证 holdout validation，将训练集数据留出一部分不参与训练，作为验证集；
    * K折验证 k-fold validation，将数据划分为大小相同的K个分区，每次取其中一个作为验证集，进行K次；
    * 重复K折验证 k-fold validation with shuffling，每次划分K个分区之前，都对数据进行打乱，进行P*K次。
4. 准备数据。
    * 格式化为张量；
    * 数据标准化处理；
    * 特征工程。
5. 开发比基准更好的模型。
    * 获得统计功效 statistical power，开发的模型可以打败纯随机基准，比如二分类问题中，acc高于0.5；
    * 配置模型，选择激活函数、损失函数、优化器等。
6. 扩大模型规模，开发过拟合的模型。
    * 添加更多的层，让每一层变得更大，或者训练更多的轮次，直到出现过拟合。
7. 模型正则化与调节超参数。
    * 不断调节模型、训练、在验证集上评估、再次调节模型，重复直到模型达到最佳性能。
    * 正则化：L1 和/或 L2 正则化，或是使用 dropout。
    * 尝试不同的架构：增加或减少层数。
    * 尝试不同的超参数组合，找到最佳配置。
    * 反复做特征工程，添加新特征或删除没有信息量的特征。

## 卷积神经网络
1. MNIST数字识别问题

<img src="imgs/k_conv1.png" width="500">

* 这是比较典型的结构，前面采取卷积层+池化层重复的形式，然后进行展开，接着几个全连接层，最后是输出分类结果的输出层。
* 在keras中
    * 卷积层，layers.Conv
    * 池化层（最大），layers.MaxPooling
    * 全连接层，layers.Dense
    * 展开层，layers.Flatten
* 卷积层和池化层，需要指定过滤器的尺寸；除了展开层，都需要指定本层所使用的激活函数；
* 最后对于mnist，模型在测试集上的acc=99.11%

2. 识别猫狗问题
* 下载Kaggle/dogs-vs-cats问题的数据，取1000张猫的照片作为训练集，500张验证集，500张测试集，狗的照片也一样。
* 建立模型，采取结构为：
    * Conv2D(32, f=3) & MaxPooling2D(f=2)
    * Conv2D(64, f=3) & MaxPooling2D(f=2)
    * Conv2D(128, f=3) & MaxPooling2D(f=2)
    * Conv2D(128, f=3) & MaxPooling2D(f=2)
    * Flatten()
    * Dense(512)
    * 输出层，Dense(1)
* 数据处理
    * 图片格式为jpg，处理的时候有以下步骤：读取图像文件，将文件解码为 RGB 像素网格，将这些像素网格转换为浮点数张量，最后再将像素值(0~255 范围内)缩放到 [0, 1] 区间。
    * 使用 Keras 的 ImageDataGenerator 类，通过生成器进行图片的处理：
        * 调用 flow_from_directory() 方法
        * 指定读取目录，图像目标大小，处理批大小，标签格式等。
* 模型训练
    * 调用 fit_generator() 方法；
    * 指定生成器，以及每轮从生成器中抽取的样本数量 steps_per_epoch，训练轮数 epochs，验证集的生成器和每次抽取的样本数量 validation_steps
* 模型评估
    * 基本上5轮以后就出现了过拟合；

<img src="imgs/cvd1.png" width="600">

* 数据增强 & dropout 解决过拟合
    * ImageDataGenerator构造参数：
        * rotation_range，图像旋转的角度范围；
        * width_shift/height_shift，图像在水平/垂直方向平移范围；
        * shear_range，图像错切变换角度范围；
        * zoom_range，图像缩放范围；
        * horizontal_flip，水平翻转；
        * fill_mode，填充新创建像素的方法。
    * 对训练集的数据，进行数据增强；
    * 改变模型结构，在展开 Flatten 后增加：
        * layers.Dropout(0.5)
* 再次评估模型
    * 过拟合有了明显改善，acc在训练集和验证集上都保持上涨趋势，训练轮数目前采取的是80，还可以再增加。

<img src="imgs/cvd2.png" width="600">