# You Only Look Once: Unified, Real-Time Object Detection [2016]
论文[链接](../papers/yolo.pdf)

## 论文内容
### YOLO简介
* 将物体检测简化为一个回归问题，从空间上划分边界框，及找到对应的分类概率；
* 只需要一个神经网络，就能完成边框和对应分类概率的预测，方便进行端到端优化；
* 实时识别，可达到45帧/秒；Fast-YOLO，网络规模更小，可以达到155帧/秒；
* 不同于滑动窗口和 R-CNN，YOLO 在训练和测试的时候，看到的都是整个图像，隐式地包含了分类以及类别外形相关的信息，所以产生将背景斑点误判为物体的假阳性错误更少；
* YOLO 检测物体的泛化能力很好，通用性高；
* 但是 YOLO 在定位的准确率方面，尤其是定位一些小物体上，表现略差一些。
### 算法简述
1. 图像划分
* 将一张图像，划分为 S*S 个格子；
* 每个格子需要预测的内容有：
    * B 个边框，一个边框包括以下5个参数：
        * x, y，表示边框中心点相对于格子的位置，所以取值在0到1之间；
        * w, h，表示边框的宽、高，相对于图像的大小，所以取值也在0到1之间；
        * confidence = Pr(Object) * IOU(truth, pred)，这个置信综合考虑了格子内是否存在物体，以及预测的物体边框和真实的物体边框交并比。
            * Pr(Object) = {0, 1}，物体中心如果落在一个格子内，那么这个物体属于这个格子；
            * IoU = (true_box ∩ pred_box) / (true_box ∪ pred_box)
    * C 个分类概率：
        * C是需要识别的物体种类，这里在预测有物体的前提下，预测物体属于每个类别的概率值。
* 所以一张图片的预测维度是，S\*S\*(B\*5+C)
* 选取 PASCAL VOC 数据集，取S=7, B=2, C=20
2. 网络结构

<img src="imgs/yolo1.png" width="600">

* 网络结构如上图所示，YOLO 共有24层CONV + 2层FC
* 输入图像为 (448, 448, 3)
* 最终输出的预测张量为 7 \* 7 \* 30
3. 模型训练
* 预训练：取模型的前20层CONV + AVG_POOLING + FC，在ImageNet上进行训练；
* 然后添加4层CONV，接上2层FC，随机初始化其参数；
* 最后一层采取线性激活函数，其余层都采取 leaky ReLU 作为激活函数；
* 模型优化目标，如果是最小化误差平方和，那么确实容易计算，但是将定位错误和分类错误混为一谈，平等处理，这样的做法不利于实现平均精度的最大化；而且注意到相同的误差，大边框其实相对小边框更容易接受。所以要对误差平方和进行一些改进：
    * 对边框定位参数，x, y, w, h，平方和前加上一个放大参数 λ_coord，这里取的是5
    * 对没有检测到物体情况下的置信 confidence，平方和前加上一个削弱参数 λ_noobj，这里取的是0.5
    * 对于宽和高，为了增强边框大小对误差的影响，取平方根的差，作为误差。
* 注意到，只有在格子里面有物体的时候，分类误差才会计入损失函数；也只有在格子负责当前物体，也就是格子预测的边框和物体真实边框交并比最高的时候，边框位置误差才会计入损失函数。
* 训练参数：
    * epochs=135, batch_size=64, β=0.9, β_decay_rate=0.0005
    * learning rate α: 1e-2 for 75 epochs, 1e-3 for 30 epochs, 1e-4 for 30 epochs
* Dropout + 数据增强，防止过拟合：
    * 第一个FC后面，加上一层 Dropout(0.5)
    * 对于数据增强，引入随机缩放，和图像的曝光、饱和度随机调整。
4. 模型局限
* 对于一些大的物体，或者中心落在划分格子边界上的物体，YOLO 需要用非最大值抑制来解决多个格子都预测到同一个物体的问题；
* YOLO 对于密集型物体的检测存在限制，比如一群鸟这种，多个物体可能互相重叠，落在一个格子上；
* YOLO 对于预测物体比例没有在训练数据中出现过，或者比例比较不同寻常的边框，泛化能力较差；
* 最后，损失函数中，计算边框误差时，对于边框本身大小的考虑还不够。